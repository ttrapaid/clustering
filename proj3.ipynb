{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "neither-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMSC426 Project 3\n",
    "# GROUP MEMBERS: Andrew Sumner (asumner1), Teimuraz Trapaidze (ttrapaid)\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "import math\n",
    "import random\n",
    "import sklearn as sk\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# CONVERT IMAGES TO GRAYSCALE?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prescribed-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\"images/dolphin\", \"images/airplanes\", \"images/Leopards\"]\n",
    "\n",
    "def get_imgs_from_folders(folders):\n",
    "    # Return to this\n",
    "    # This must be all images, not just dolphin images, and we must track the label\n",
    "    image_sets = []\n",
    "    for folder in folders:\n",
    "        images = []\n",
    "        i = 0\n",
    "        for filename in os.listdir(folder):\n",
    "            i = i + 1\n",
    "            image = img.imread(os.path.join(folder,filename))\n",
    "            images.append(image)\n",
    "            if i >= 65:\n",
    "                break\n",
    "        image_sets.append(images)\n",
    "    return image_sets\n",
    "\n",
    "all_images = get_imgs_from_folders(folders)\n",
    "\n",
    "images = all_images[0] # REMOVE THIS LATER!!!!!!!!!!!!!!!!\n",
    "#print(images)\n",
    "\n",
    "# ensure feature imbalance is taken care of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "wired-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting train and test\n",
    "# note that we already know the labels since the folders are still\n",
    "# separated within the output data structure (for now)\n",
    "train_subsets = []\n",
    "test_subsets = []\n",
    "for img_set in all_images:\n",
    "    train_x, test_x = train_test_split(img_set, test_size=0.1)\n",
    "    train_subsets.append(train_x)\n",
    "    test_subsets.append(test_x)\n",
    "    \n",
    "#print(len(test_subsets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "noticed-growing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIN NUM KP =  34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "36\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "36\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "35\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "35\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "36\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "35\n",
      "36\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "35\n",
      "34\n",
      "\n",
      "(6674, 128)\n"
     ]
    }
   ],
   "source": [
    "# supposedly we get descriptors for all images in a category, then \n",
    "# stack ? \n",
    "desc_all_imgs = []\n",
    "kp_all_imgs = []\n",
    "min_num_kp = 999999999999999\n",
    "\n",
    "# FIRST LOOP FINDS MIN KP BOUND\n",
    "for img_set in all_images:\n",
    "    for image in img_set:\n",
    "        sift = cv2.SIFT_create()\n",
    "        kp, descriptors = sift.detectAndCompute(image, None)\n",
    "        if len(kp) < min_num_kp:\n",
    "            min_num_kp = len(kp)\n",
    "\n",
    "print(\"MIN NUM KP = \", min_num_kp)\n",
    "# SECOND LOOP FINDS BEST KEYPOINTS WHERE ALL IMGS HAVE SAME (MIN) NUM\n",
    "for img_set in all_images:\n",
    "    for image in img_set:\n",
    "        sift = cv2.SIFT_create(nfeatures=min_num_kp)\n",
    "        kp, descriptors = sift.detectAndCompute(image, None)\n",
    "        #TRIM DESCRIPTORS HERE\n",
    "        print(len(descriptors))\n",
    "        desc_all_imgs.append(descriptors)\n",
    "        kp_all_imgs = kp_all_imgs + kp\n",
    "\n",
    "#     print(descriptors.shape)\n",
    "#     for pt, desc in zip(kp, descriptors):\n",
    "#         (x,y) = pt.pt\n",
    "#         print((x,y), desc)\n",
    "\n",
    "desc_all_imgs = tuple(desc_all_imgs)\n",
    "desc_all_imgs = np.vstack(desc_all_imgs)\n",
    "#print(desc_all_imgs)\n",
    "print()\n",
    "print(desc_all_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "proved-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(keypoints, descriptors, k):\n",
    "    num_descs = len(keypoints)\n",
    "    \n",
    "    center_descs = []\n",
    "    # initial random k centers\n",
    "    for i in range(k):\n",
    "        center = random.randint(0, num_descs-1)\n",
    "        center_descs.append(descriptors[center])\n",
    "        \n",
    "    check = False\n",
    "    \n",
    "    while (not check):\n",
    "        clusters = {i:[] for i in range(k)}\n",
    "            \n",
    "        for descriptor in descriptors:\n",
    "            closest = 99999999999\n",
    "            i = 0\n",
    "            for center_desc in center_descs:\n",
    "#                 dist = np.sum((center_desc-descriptor)**2)\n",
    "\n",
    "                dist = np.linalg.norm(center_desc - descriptor)\n",
    "                if dist < closest:\n",
    "                    closest = dist\n",
    "                    closest_center = i\n",
    "                i += 1\n",
    "\n",
    "            clusters[closest_center].append(descriptor)\n",
    "            \n",
    "        \n",
    "#         for key, value in clusters.items():\n",
    "#             print(key, len(value))\n",
    "                \n",
    "#         print(\"\\n\\n\")\n",
    "        \n",
    "        old_centers = center_descs\n",
    "        center_descs = []\n",
    "        \n",
    "        print(len(old_centers))\n",
    "        \n",
    "        for center_num, cluster in clusters.items():\n",
    "            if (len(cluster) > 0):\n",
    "                cluster = np.vstack(cluster)\n",
    "                new_center = np.sum(cluster, axis=0)/np.linalg.norm(cluster)\n",
    "                center_descs.append(new_center)\n",
    "        \n",
    "        check = True\n",
    "        for old, new in zip(old_centers, center_descs):\n",
    "            if not np.array_equal(old, new):\n",
    "                check = False\n",
    "                break\n",
    "        \n",
    "        \n",
    "    return center_descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "sought-proof",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "382\n",
      "193\n",
      "74\n",
      "22\n",
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# i havent checked this yet, but if you were to sum the number of key \n",
    "# points in each cluster, it should equal the number of descriptors \n",
    "\n",
    "# this is for one image\n",
    "\n",
    "# issue: why is the number of clusters decreasing with each iteration\n",
    "\n",
    "centers = clustering(kp_all_imgs, desc_all_imgs, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "representative-circuit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 6149.1064,  4379.013 ,  3884.8135,  3795.2483,  4707.0557,\n",
      "        3304.2722,  2870.352 ,  3501.7734, 16653.69  ,  7411.3667,\n",
      "        4594.0312,  4052.2136,  5321.038 ,  4067.711 ,  4378.5083,\n",
      "        7916.0537, 14907.638 ,  6536.7295,  3713.6843,  3844.808 ,\n",
      "        6236.7295,  5107.3403,  5534.58  ,  8050.129 ,  5575.2456,\n",
      "        3180.528 ,  2567.8274,  3237.7004,  5179.3887,  4108.5703,\n",
      "        4314.0728,  4681.1494,  9375.66  ,  4822.838 ,  4690.8594,\n",
      "        5341.5845,  6624.0415,  4589.565 ,  3512.6487,  4338.542 ,\n",
      "       25114.512 ,  8782.263 ,  6607.6514,  7979.6733,  8962.092 ,\n",
      "        6228.6895,  5972.268 , 12614.914 , 22628.016 , 10447.993 ,\n",
      "        5091.921 ,  6150.0776, 10965.147 ,  9869.316 ,  7934.5415,\n",
      "        9681.33  ,  8084.6577,  3900.5435,  3258.2468,  4888.5547,\n",
      "        7647.3975,  6074.417 ,  5255.36  ,  4887.3896,  9441.145 ,\n",
      "        4226.2944,  3370.2224,  4619.899 ,  6684.865 ,  5332.224 ,\n",
      "        4822.3716,  4879.0005, 25093.615 , 12480.178 ,  5848.64  ,\n",
      "        6184.1787,  9004.194 ,  7991.7915,  6721.9185,  8846.504 ,\n",
      "       22733.854 ,  9619.42  ,  7690.393 ,  9790.549 , 11023.019 ,\n",
      "        6339.772 ,  5282.237 , 10516.079 ,  8129.9062,  5015.251 ,\n",
      "        5012.2993,  6072.8633,  7832.4697,  5052.421 ,  3345.0542,\n",
      "        3850.906 ,  6173.226 ,  3288.7751,  2742.1802,  3335.888 ,\n",
      "        4819.3423,  3858.1304,  3929.4016,  4502.7573, 16889.059 ,\n",
      "        7821.8276,  4295.1577,  3946.1028,  5385.668 ,  4082.5476,\n",
      "        4616.947 ,  7475.7246, 14995.921 ,  8259.243 ,  5555.5537,\n",
      "        5057.198 ,  6336.354 ,  4031.7063,  3819.834 ,  6456.253 ,\n",
      "        5546.3877,  4779.376 ,  4510.7583,  4143.5264,  5216.1313,\n",
      "        3520.7275,  2674.5596,  3267.1023], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_histogram(descriptors, centers): # descriptors is for a single image\n",
    "    hist_arr = []\n",
    "    num_bins = len(centers)\n",
    "    for row in descriptors:\n",
    "        min_dist = 9999999999999999999\n",
    "        min_center_idx = -1\n",
    "        center_idx = -1\n",
    "        for center in centers:\n",
    "            center_idx = center_idx + 1\n",
    "            dist = np.linalg.norm(row - center)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                min_center_idx = center_idx\n",
    "        hist_arr.append(min_center_idx)\n",
    "    hist = np.histogram(hist_arr, bins=num_bins)\n",
    "    plt.hist(hist_arr, bins=num_bins)\n",
    "    plt.show()\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this later once we have our test and train cleaned up\n",
    "\n",
    "svclassifier = sk.svm.SVC(kernel='linear')\n",
    "svclassifier.fit(x_train, y_train)\n",
    "y_test_pred = svclassifier.predict(x_test)\n",
    "\n",
    "print(sk.metrics.classification_report(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
